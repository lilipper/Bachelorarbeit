/pfs/work9/workspace/scratch/ma_lilipper-lippert_bachelorthesis_ws/miniconda3/envs/diffusion-classifier/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/pfs/work9/workspace/scratch/ma_lilipper-lippert_bachelorthesis_ws/miniconda3/envs/diffusion-classifier/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]Loading pipeline components...:  17%|█▋        | 1/6 [00:00<00:01,  4.65it/s]Loading pipeline components...:  67%|██████▋   | 4/6 [00:00<00:00,  5.70it/s]Loading pipeline components...:  83%|████████▎ | 5/6 [00:00<00:00,  5.48it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  5.22it/s]Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  5.32it/s]
/pfs/work9/workspace/scratch/ma_lilipper-lippert_bachelorthesis_ws/Bachelorarbeit/diffusion_classifier/adapter_multichannel/train_dc_with_original_cn_multichannel_acc.py:424: FutureWarning: Accessing config attribute `in_channels` directly via 'ControlNetModel' object attribute is deprecated. Please access 'in_channels' over 'ControlNetModel's config object instead, e.g. 'unet.config.in_channels'.
  print("controlnet config in/out:", getattr(controlnet, "in_channels", None), getattr(controlnet, "out_channels", None))
/pfs/work9/workspace/scratch/ma_lilipper-lippert_bachelorthesis_ws/miniconda3/envs/diffusion-classifier/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
